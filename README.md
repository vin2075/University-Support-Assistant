# ğŸ“ University RAG Assistant

A **production-grade Retrieval-Augmented Generation (RAG)** chat assistant built with:
- **OpenRouter** â€” LLM gateway (free tier) for grounded response generation
- **sentence-transformers** (`all-MiniLM-L6-v2`) â€” Local embeddings, no API key needed
- **FastAPI** (Python) â€” Async REST backend
- **React + Vite + Tailwind CSS** â€” Modern reactive frontend
- **NumPy** â€” Cosine similarity vector math

---

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USER (Browser)                             â”‚
â”‚                    React Chat Interface                             â”‚
â”‚          sessionId stored in localStorage                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚  POST /api/chat
                               â”‚  { sessionId, message }
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       FastAPI Backend                               â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Embed Query   sentence-transformers (LOCAL, no API)      â”‚  â”‚
â”‚  â”‚     "How to reset?"  â†’  [0.12, -0.43, 0.87, ...]  (384-dim) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  2. Cosine Similarity Search    vector_store.json            â”‚  â”‚
â”‚  â”‚     Query Vector vs all chunk vectors (NumPy)                â”‚  â”‚
â”‚  â”‚     â†’ sorted by score â†’ top 3 above threshold 0.30          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  3. Build Augmented Prompt                                   â”‚  â”‚
â”‚  â”‚     SYSTEM: "Answer using ONLY the context below..."         â”‚  â”‚
â”‚  â”‚     CONTEXT: [Source 1 â€” IT Policy]\n...\n[Source 2]\n...   â”‚  â”‚
â”‚  â”‚     HISTORY: last 5 conversation pairs                       â”‚  â”‚
â”‚  â”‚     QUESTION: "How do I reset my password?"                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  4. LLM Generation       OpenRouter (free model)             â”‚  â”‚
â”‚  â”‚     temp=0.2  max_tokens=1024                                â”‚  â”‚
â”‚  â”‚     â†’ grounded, factual answer                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  { reply, tokensUsed,
                                 â”‚    retrievedChunks, scores }
                                 â–¼
                           React renders response
                    Sidebar shows similarity scores + token count
```

---

## âœ… What I Achieved

### Core RAG Pipeline
- Built a **fully functional RAG system** from scratch with real embedding-based retrieval (not keyword matching)
- Created a **10-document university knowledge base** covering policies on attendance, grading, housing, IT, financial aid, library, parking, health, registration, and academic integrity
- Implemented **document chunking with 50-word overlap** so context is never lost at chunk boundaries
- Generated **384-dimensional embedding vectors** locally using `sentence-transformers`
- Built **cosine similarity search** using NumPy to retrieve the top-3 most relevant chunks per query
- Applied a **similarity threshold (0.30)** so irrelevant chunks are filtered out before reaching the LLM
- Constructed a **grounded system prompt** that forces the LLM to answer only from retrieved context

### Backend (FastAPI)
- Built a complete REST API with `/api/chat`, `/api/health`, `/api/session/new`, `/api/session/{id}` endpoints
- Implemented **in-memory session management** to maintain last 5 conversation pairs per user
- Added **strict CORS policy** â€” only allows `http://localhost:5173` (the React dev server)
- Added structured error handling for rate limits, timeouts, invalid keys, and empty responses

### Frontend (React + Vite)
- Built a full chat UI with message bubbles, timestamps, and markdown rendering
- Added **animated typing indicator** (3-dot bounce) while waiting for LLM response
- Implemented **auto-scroll** to latest message
- Added **session persistence** via `localStorage` so the session survives page refreshes
- Built a sidebar showing **similarity scores as progress bars**, token usage, and suggested questions
- Suggested questions are **clickable and send directly** to the chat

### Integration
- Connected frontend to backend via **Vite proxy** â€” no CORS issues during development
- Only **one external API** is used at runtime (OpenRouter) â€” embeddings run fully locally

---

## ğŸš§ Problems I Faced & How I Solved Them

### Problem 1 â€” Mixed API Versions in Code
**What happened:** The project went through multiple iterations. Early versions used Anthropic's Claude API + Voyage AI for embeddings. When switching to OpenRouter, some files were updated while others were not. This caused errors like:
```
OSError: VOYAGE_API_KEY is not set. Check your .env file.
```
even after creating a `.env` with `OPENROUTER_API_KEY`.

**Root cause:** There were two different `server.py` files floating around â€” one still importing `voyageai` and `anthropic`, and a newer one using `openai` (pointing at OpenRouter) + `sentence_transformers`. The wrong one was being run.

**Solution:** Completely replaced `server.py` with the clean OpenRouter + sentence-transformers version. Removed all references to `voyageai` and `anthropic` packages. Updated `requirements.txt` accordingly.

---

### Problem 2 â€” `.env` File Not Being Loaded
**What happened:** Even after creating `.env` with the correct `OPENROUTER_API_KEY`, the server kept throwing:
```
OSError: OPENROUTER_API_KEY is not set.
```

**Root cause:** The `.env` file was named `.env.example` or placed in the wrong directory. FastAPI loads the `.env` using `load_dotenv(BASE_DIR / ".env")` where `BASE_DIR` is the `backend/` folder. The file must be at `backend/.env` exactly.

**Solution:** Created the file correctly at `E:\rag-assistant\backend\.env` using:
```powershell
New-Item -Name ".env" -ItemType File
notepad .env
```

---

### Problem 3 â€” Frontend Could Not Reach Backend (ECONNREFUSED)
**What happened:** The React frontend showed this error in the Vite terminal:
```
Error: connect ECONNREFUSED ::1:8000
```
Messages sent from the UI never reached the backend.

**Root cause:** `vite.config.js` had `target: "http://localhost:8000"`. On Windows with Node.js 18+, `localhost` resolves to IPv6 (`::1`) by default. But `uvicorn` binds to IPv4 (`127.0.0.1`). So the proxy was connecting to the wrong address.

**Solution:** Changed the proxy target to the explicit IPv4 address:
```js
// BROKEN
target: "http://localhost:8000"

// FIXED
target: "http://127.0.0.1:8000"
```

---

### Problem 4 â€” OpenRouter 404: Model Not Found
**What happened:** After fixing the connection issue, the chat returned:
```
âš ï¸ Error: OpenRouter error: Error code: 404 -
{'error': {'message': 'No endpoints found for mistralai/mistral-7b-instruct:free.'}}
```

**Root cause:** Free model availability on OpenRouter changes frequently. The model name `mistralai/mistral-7b-instruct:free` that was referenced in earlier instructions was no longer available as a free endpoint by the time the project was running.

**What I tried:**
- `mistralai/mistral-7b-instruct:free` â†’ 404
- `deepseek/deepseek-chat-v3-0324:free` â†’ 404
- Multiple other model names â†’ 404

**Solution:** Used `openrouter/free` â€” OpenRouter's own automatic free model router that picks whatever free model is currently available. This never 404s regardless of which individual models come and go. Set in `.env`:
```
OPENROUTER_MODEL=openrouter/free
```

---

### Problem 5 â€” Suggested Questions Were Dead Buttons
**What happened:** Clicking any suggested question in the sidebar did nothing. The text did not appear in the chat or get sent to the backend.

**Root cause:** The `Sidebar.jsx` component rendered the question buttons but had no `onClick` handler:
```jsx
// Dead button â€” no action
<button key={q} className="...">
  {q}
</button>
```
Also, `App.jsx` never passed the `handleSend` function down to `Sidebar` as a prop.

**Solution:**
1. Added `onSend` prop to `Sidebar`
2. Wired each button's `onClick` to call `onSend(q)`
3. Passed `onSend={handleSend}` from `App.jsx` to `<Sidebar />`

```jsx
// Fixed â€” clicking sends the question
<button key={q} onClick={() => onSend(q)} className="...">
  {q}
</button>
```

---

### Problem 6 â€” API Key Accidentally Exposed
**What happened:** While debugging, the actual `OPENROUTER_API_KEY` value was pasted in a chat message, making it publicly visible.

**Solution:** Immediately went to https://openrouter.ai/keys, deleted the compromised key, and generated a new one. Lesson learned: never paste real API keys anywhere â€” use placeholders like `sk-or-v1-xxxx` in documentation.

---

## ğŸ How I Concluded

After working through all the above problems, the final working stack is:

| Component | Original Plan | Final Solution | Reason for Change |
|-----------|--------------|----------------|-------------------|
| LLM | Anthropic Claude API | OpenRouter (free tier) | Cost â€” OpenRouter provides free LLM access |
| Embeddings | Voyage AI (cloud API) | sentence-transformers (local) | Eliminated a second API key requirement |
| Frontend proxy | `localhost:8000` | `127.0.0.1:8000` | IPv6 vs IPv4 resolution on Windows |
| Free model | `mistral-7b-instruct:free` | `openrouter/free` | Specific free models kept going offline |

The key insight was that **sentence-transformers running locally** was a better choice than a cloud embedding API for this use case. It removes one API dependency, works offline after the initial model download, and is fast enough for development use.

The final application successfully demonstrates all core RAG concepts:
- Real embedding-based retrieval (not keyword search)
- Cosine similarity with threshold filtering
- Context-injected grounded prompting
- Conversation history management
- Full-stack integration with React frontend

---

## ğŸ”„ RAG Workflow Explanation

**RAG (Retrieval-Augmented Generation)** prevents hallucinations by grounding the LLM in real facts:

| Step | What Happens |
|------|-------------|
| 1. **Offline Ingestion** | Documents â†’ chunked â†’ embedded locally â†’ saved to `vector_store.json` |
| 2. **Query Embedding** | User question â†’ embedding vector (same local model as documents) |
| 3. **Similarity Search** | Cosine similarity of query vs. every chunk vector |
| 4. **Context Injection** | Top-3 relevant chunks injected into the LLM prompt |
| 5. **Grounded Response** | LLM reads ONLY the injected context to answer |

**Without RAG:** LLM guesses from training data â†’ may hallucinate
**With RAG:** LLM reads your specific documents â†’ factually grounded

---

## ğŸ“ Embedding Strategy

- **Model:** `all-MiniLM-L6-v2` â€” runs locally, ~90 MB download, 384-dimensional vectors
- **Chunk Size:** ~300 words with 50-word overlap
- **Similarity Threshold:** 0.30 (tuned lower than cloud models since MiniLM scores run in a different range)
- **Storage:** `vector_store.json` stores both the text and its vector â€” no re-embedding needed at query time

### Chunking with Overlap

```
Original: "... [word 1 ... word 300] [word 251 ... word 550] ..."
                 â””â”€â”€ Chunk 1 â”€â”€â”˜      â””â”€â”€ Chunk 2 â”€â”€â”˜
                           â””â”€â”€overlap (50w)â”€â”€â”˜
```

---

## ğŸ“ Similarity Search Explanation

We use **cosine similarity** â€” the angle between two vectors in high-dimensional space:

```
cosine_similarity(A, B) = (A Â· B) / (||A|| Ã— ||B||)
```

- `1.0` = identical meaning
- `0.0` = completely unrelated
- Threshold `0.30` = chunks below this score are discarded

```python
# From utils/vector_math.py
def cosine_similarity(vec_a, vec_b):
    a, b = np.array(vec_a), np.array(vec_b)
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))
```

---

## ğŸ’¬ Prompt Design Reasoning

```
SYSTEM: "Answer ONLY using the context provided. Say 'I don't know' if insufficient."
          â†‘ Hard grounding rule â†’ prevents hallucination

RETRIEVED CONTEXT:
[Source 1 â€” IT Policy]: "... password reset steps ..."
[Source 2 â€” Registration]: "..."
          â†‘ Real factual data injected at runtime

CONVERSATION HISTORY: (last 5 turns)
User: "What is the late fee?"
Assistant: "The late fee is $150..."
          â†‘ Maintains conversational continuity

USER QUESTION: "Is there a grace period?"
          â†‘ Actual user input

ANSWER:
```

**Temperature = 0.2** â€” Low randomness ensures consistent, factual answers.

---

## ğŸš€ Setup Instructions

### Prerequisites
- Python 3.9+
- Node.js 18+
- OpenRouter API key: https://openrouter.ai/keys (free signup)

---

### Step 1: Clone & Configure

```bash
git clone <your-repo-url>
cd rag-assistant
```

Create `backend/.env`:
```
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENROUTER_MODEL=openrouter/free
```

---

### Step 2: Install Python dependencies

```bash
cd backend
pip install openai sentence-transformers fastapi uvicorn python-dotenv numpy pydantic
```

---

### Step 3: Generate the Vector Store (run once)

```bash
python scripts/ingest.py
```

Expected output:
```
ğŸ“¦  Loading embedding model 'all-MiniLM-L6-v2' ...
âœ…  Model ready.
ğŸ“‚  Loading documents... Found 10 document(s).
âœ‚ï¸   Chunking documents... Generated 13 chunk(s).
ğŸ”¢  Generating embeddings locally...
âœ…  Vector store saved! 13 chunks, 384 dimensions.
```

---

### Step 4: Start the Backend

```bash
uvicorn server:app --reload --port 8000
```

Verify at: http://127.0.0.1:8000/api/health

---

### Step 5: Start the Frontend

```bash
cd frontend
npm install
npm run dev
```

Visit: **http://localhost:5173**

---

## ğŸ“ Project Structure

```
rag-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ docs.json              # 10 university policy documents
â”‚   â”‚   â””â”€â”€ vector_store.json      # Chunks + embeddings (auto-generated)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ ingest.py              # Chunking + local embedding pipeline
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ vector_math.py         # Cosine similarity + top-k retrieval
â”‚   â”œâ”€â”€ server.py                  # FastAPI entry point
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx      # Scrollable message list
â”‚   â”‚   â”‚   â”œâ”€â”€ Message.jsx         # Individual message bubble
â”‚   â”‚   â”‚   â”œâ”€â”€ InputBar.jsx        # Text input + send button
â”‚   â”‚   â”‚   â”œâ”€â”€ TypingIndicator.jsx # Animated dots
â”‚   â”‚   â”‚   â””â”€â”€ Sidebar.jsx         # Session info + suggestions
â”‚   â”‚   â”œâ”€â”€ App.jsx                 # Root component + session logic
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

---

## ğŸ”Œ API Reference

### `GET /api/health`
```json
{
  "status": "ok",
  "chunksLoaded": 13,
  "llmModel": "openrouter/free",
  "embeddingModel": "all-MiniLM-L6-v2",
  "externalAPIs": ["openrouter.ai"]
}
```

### `POST /api/chat`
**Request:**
```json
{ "sessionId": "abc123", "message": "How do I reset my password?" }
```
**Response:**
```json
{
  "reply": "Students can reset their university portal password at account.university.edu...",
  "tokensUsed": 312,
  "retrievedChunks": 1,
  "scores": [0.842],
  "sessionId": "abc123"
}
```

---

## ğŸ›¡ï¸ Error Handling

| Scenario | Status | Response |
|----------|--------|----------|
| Empty message | 422 | Validation error |
| Message > 2000 chars | 422 | Validation error |
| OpenRouter rate limit | 429 | Retry message |
| OpenRouter timeout | 504 | Timeout message |
| Model not found (404) | 502 | API error detail |
| No relevant chunks | 200 | Safe fallback text |

---

## ğŸ“Š Knowledge Base Topics

1. Academic Integrity Policy
2. Attendance and Absence Policy
3. Tuition Payment and Financial Aid
4. Password Reset and IT Account Access
5. Library Resources and Borrowing Policy
6. Campus Housing and Dormitory Rules
7. Grading Scale and GPA Calculation
8. Student Health and Counseling Services
9. Course Registration and Drop/Add Policy
10. Campus Parking and Transportation